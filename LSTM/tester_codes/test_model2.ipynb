{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "#from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datas/train_passengers_copy.csv')\n",
    "#Variables for training\n",
    "cols = list(df)[1:3]\n",
    "df_for_training = df[cols].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_for_training)\n",
    "df_for_training_scaled = scaler.transform(df_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features. \n",
    "#In this example, the n_features is 5. We will make timesteps = 14 (past days data used for training). \n",
    "\n",
    "#Empty lists to be populated using formatted training data\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past = 3  # Number of past days we want to use to predict the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape == (141, 3, 2).\n",
      "trainY shape == (141, 1).\n"
     ]
    }
   ],
   "source": [
    "#Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
    "#In my example, my df_for_training_scaled has a shape (12823, 5)\n",
    "#12823 refers to the number of data points and 5 refers to the columns (multi-variables).\n",
    "for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n",
    "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "\n",
    "print('trainX shape == {}.'.format(trainX.shape))\n",
    "print('trainY shape == {}.'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "test_model = tf.keras.models.load_model(\"../saved_param/test_model1/\")\n",
    "weights_test_model_1 = test_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.layers.LSTM(3, input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True, return_state=True)\n",
    "init_weights = model(np.array([trainX[1]])) # you need to pass an input to initialize the weights then setup the weights manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(weights_test_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.28213406,  0.40180504,  0.10323656,  0.49266553,  0.59737396,\n",
       "         -0.27416527, -0.6140406 , -0.22036755, -0.36234343,  0.11618108,\n",
       "         -0.40446782, -0.05731392],\n",
       "        [ 0.09265673, -0.55035496, -0.0250091 ,  0.10383672, -0.03438932,\n",
       "          0.44054282, -0.02767795,  0.35591948, -0.076204  , -0.6510474 ,\n",
       "         -0.4240626 , -0.43181473]], dtype=float32),\n",
       " array([[-0.11440527, -0.09116384,  0.10766367,  0.41458526,  0.13482785,\n",
       "          0.02425341, -0.14716567,  0.09884649, -0.07846723, -0.2423919 ,\n",
       "          0.7091871 ,  0.42080373],\n",
       "        [-0.09434418,  0.6440063 , -0.16892694,  0.09986253, -0.29395232,\n",
       "         -0.35163632, -0.18524946,  0.01135916, -0.2985677 ,  0.35922354,\n",
       "          0.23562133, -0.1401508 ],\n",
       "        [ 0.12497412,  0.13285607,  0.29592115, -0.17216626, -0.05532025,\n",
       "         -0.09946106, -0.70869935,  0.2606318 ,  0.50013614, -0.11444857,\n",
       "         -0.03364325, -0.04491055]], dtype=float32),\n",
       " array([0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\n",
       " array([[[-0.00752289,  0.04412096, -0.0144942 ],\n",
       "         [-0.01602702,  0.06958452, -0.02986364],\n",
       "         [-0.01964575,  0.08610261, -0.04356184]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-0.01964575,  0.08610261, -0.04356184]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-0.0476364 ,  0.2013372 , -0.10137359]], dtype=float32)>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.array([trainX[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02702703, 0.8       ],\n",
       "       [0.05405405, 0.6       ],\n",
       "       [0.04826255, 0.6       ]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListWrapper([None, None])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_model = tf.keras.layers.LSTMCell(3, input_shape=(trainX.shape[1], trainX.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() missing 1 required positional argument: 'states'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [145], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cell_model\u001b[38;5;241m.\u001b[39mbuild(input_shape\u001b[38;5;241m=\u001b[39m(trainX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], trainX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcell_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Electrical Engineering Files\\Electrical engineering files\\OJT 1\\EROVOUTIKA\\activities\\deep_learning\\deep_learning_code\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Electrical Engineering Files\\Electrical engineering files\\OJT 1\\EROVOUTIKA\\activities\\deep_learning\\deep_learning_code\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: call() missing 1 required positional argument: 'states'"
     ]
    }
   ],
   "source": [
    "cell_model.build(input_shape=(trainX.shape[1], trainX.shape[2]))\n",
    "cell_model(trainX[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('deep_learning_code')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94ae5b382a51005fca8da01575be2d2af1d447d51e335e66e884b29c6c326d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
